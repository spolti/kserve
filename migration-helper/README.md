# ModelMesh to KServe Raw Deployment Migration Helper

A bash script that migrates InferenceServices from ModelMesh serving to KServe Raw deployment mode. This tool handles bulk migrations with interactive pagination, template selection, and storage configuration management.

## What it does

- **Migrates models**: Converts ModelMesh InferenceServices to KServe Raw deployment
- **Preserves configuration**: Maintains route exposure, authentication, and storage settings
- **Handles secrets**: Clones and manages storage and authentication secrets
- **Creates resources**: Generates ServingRuntimes, ServiceAccounts, Roles, and RoleBindings
- **Pagination support**: Interactive navigation for namespaces with hundreds of models
- **Dry-run mode**: Preview changes without applying them

## Requirements

- `oc` (OpenShift CLI)
- `yq` (YAML processor)
- `openssl`
- Access to both source and target namespaces
- OpenShift cluster login

## Usage

```bash
./modelmesh-to-raw.sh --from-ns <source-namespace> --target-ns <target-namespace> [OPTIONS]
```

### Parameters

| Parameter | Description | Required |
|-----------|-------------|----------|
| `--from-ns` | Source namespace containing ModelMesh InferenceServices | âœ… |
| `--target-ns` | Target namespace for KServe Raw deployment | âœ… |
| `--ignore-existing-ns` | Skip check if target namespace already exists | âŒ |
| `--debug` | Show complete processed resources and wait for confirmation | âŒ |
| `--dry-run` | Save all YAML resources to local directory without applying | âŒ |
| `--page-size` | Number of InferenceServices to display per page (default: 10) | âŒ |
| `-h, --help` | Show help message | âŒ |

## Examples

### Basic Migration
```bash
./modelmesh-to-raw.sh --from-ns modelmesh-serving --target-ns kserve-raw
```

### Migration with Pagination
```bash
./modelmesh-to-raw.sh --from-ns large-namespace --target-ns kserve-raw --page-size 5
```

### Dry Run Mode
```bash
./modelmesh-to-raw.sh --from-ns modelmesh-serving --target-ns kserve-raw --dry-run
```

### Debug Mode with Existing Namespace
```bash
./modelmesh-to-raw.sh --from-ns modelmesh-serving --target-ns kserve-raw --ignore-existing-ns --debug
```

## Example Output

### Successful Migration
```
ModelMesh to KServe Raw Deployment Migration Helper
==================================================

Source namespace (ModelMesh): modelmesh-serving
Target namespace (KServe Raw): kserve-raw

ğŸ” Checking OpenShift login status...
âœ“ Logged in as: developer
âœ“ Connected to: https://api.cluster.local:6443

ğŸ” Verifying ModelMesh configuration in source namespace...
âœ“ ModelMesh is enabled in namespace 'modelmesh-serving'

ğŸš€ Setting up target namespace for KServe Raw deployment...
ğŸ—ï¸ Creating target namespace 'kserve-raw'...
âœ“ Target namespace 'kserve-raw' created successfully
âœ“ Dashboard label applied to namespace 'kserve-raw'
âœ“ modelmesh-enabled label set to false on namespace 'kserve-raw'

ğŸ” Discovering InferenceServices in source namespace 'modelmesh-serving'...
âœ“ Found 3 InferenceService(s) in namespace 'modelmesh-serving'

ğŸ“¦ InferenceServices (Page 1/1, showing items 1-3 of 3):
=======================================================================================
[1] Name: mnist-model
    Status: Ready
    Runtime: ovms
    Model Format: onnx
    Storage: s3://my-bucket/mnist/

[2] Name: sklearn-model
    Status: Ready
    Runtime: ovms
    Model Format: sklearn
    Storage: s3://my-bucket/sklearn/

[3] Name: custom-model
    Status: Ready
    Runtime: custom-runtime
    Model Format: tensorflow
    Storage: s3://my-bucket/tensorflow/

ğŸ¤” Selection options:
====================
â€¢ 'all' - Select all InferenceServices across all pages
â€¢ '3 4' - Select specific items by number (e.g., '3 4' to select items 3 and 4)

â€¢ 'q' - Quit migration

Your selection: all
âœ“ Selected all 3 InferenceService(s) for migration

ğŸ”§ Preparing serving runtimes for selected models...
âœ“ All serving runtimes created successfully

ğŸ”„ Processing InferenceServices for Raw Deployment migration...
===================================================================
ğŸ”§ Transforming InferenceService 'mnist-model' for Raw Deployment...

ğŸ” Secret Management for InferenceService 'mnist-model'
=======================================================
ğŸ“ Current Storage Configuration:
   Path: models/mnist/1/
   URI: s3://my-bucket/mnist/

âœ“ Selected all 3 InferenceService(s) for migration

ğŸ‰ Migration completed successfully!
======================================

ğŸ“Š Migration Summary:
  â€¢ Source namespace: modelmesh-serving (ModelMesh)
  â€¢ Target namespace: kserve-raw (KServe Raw)
  â€¢ InferenceServices migrated: 3
  â€¢ Models: mnist-model, sklearn-model, custom-model

ğŸ’¡ Next steps:
  â€¢ Verify your migrated models are working: oc get inferenceservice -n kserve-raw
  â€¢ Check ServingRuntimes: oc get servingruntime -n kserve-raw
  â€¢ Test model endpoints for functionality

ğŸ Migration helper completed!
```

### Pagination Example
```
ğŸ“¦ InferenceServices (Page 1/3, showing items 1-10 of 25):
=======================================================================================
[1] Name: model-001
[2] Name: model-002
...
[10] Name: model-010

ğŸ¤” Selection options:
====================
â€¢ 'all' - Select all InferenceServices across all pages
â€¢ '3 4' - Select specific items by number (e.g., '3 4' to select items 3 and 4)

ğŸ“„ Navigation:
==============
â€¢ 'n' - Next page
â€¢ 'l' - Last page
â€¢ 'goto:X' - Go to specific page X (e.g., 'goto:3')

â€¢ 'q' - Quit migration

Your selection: n
ğŸ“„ Moving to page 2...

ğŸ“¦ InferenceServices (Page 2/3, showing items 11-20 of 25):
=======================================================================================
[11] Name: model-011
[12] Name: model-012
...
```

### Dry Run Example
```
ğŸ Dry-run completed successfully!

ğŸ“‹ DRY-RUN SUMMARY
==================

All YAML resources have been saved to: migration-dry-run-20241007-143022

ğŸ“Š Resources saved:
  â€¢ Original ModelMesh resources: 9 files
  â€¢ New KServe Raw resources: 15 files

ğŸ“‚ Directory structure:
  migration-dry-run-20241007-143022/
  â”œâ”€â”€ original-resources/     (ModelMesh resources for comparison)
  â”‚   â”œâ”€â”€ inferenceservice/
  â”‚   â”œâ”€â”€ servingruntime/
  â”‚   â””â”€â”€ secret/
  â””â”€â”€ new-resources/          (KServe Raw resources to apply)
      â”œâ”€â”€ inferenceservice/
      â”œâ”€â”€ servingruntime/
      â”œâ”€â”€ secret/
      â”œâ”€â”€ serviceaccount/
      â”œâ”€â”€ role/
      â””â”€â”€ rolebinding/

ğŸ’¡ Next steps:
  1. Review the generated YAML files in migration-dry-run-20241007-143022
  2. Compare original vs new resources to understand the migration changes
  3. When ready, apply the resources manually:
     find migration-dry-run-20241007-143022/new-resources -name '*.yaml' -exec oc apply -f {} \;
  4. Or re-run this script without --dry-run to perform the actual migration
```

## Features

### Interactive Template Selection
When custom ServingRuntimes are detected, the script presents available templates:
```
ğŸ¤” Please select a template for model 'custom-model' from the available ones:
=========================================================================================
    [1] kserve-ovms (OpenVINO Model Server)
    [2] kserve-tensorflow (TensorFlow Serving)
    [3] kserve-pytorch (PyTorch Serving)
    [d] Use default: kserve-ovms (OpenVINO Model Server)
    [m] Enter template name manually

  Your choice (1-3/d/m): 1
```

### Storage Configuration Management
For each model, you can update storage paths for OpenVINO compatibility:
```
ğŸ“ Storage Configuration for 'mnist-model':
   Current path: models/mnist/
   Current storageUri: s3://my-bucket/mnist/

ğŸ¤” Do you want to update the storage configuration for this model?
   1) Keep current configuration
   2) Enter a new path S3 OpenVINO versioned compatible 'storage.path'
   3) Enter a new URI (storageUri)
   4) Skip this model

Your choice (1/2/3/4): 2
ğŸ“ Enter the new storage path (e.g., openvino/mnist/):
New path: models/mnist/1/
âœ… Updated path to: models/mnist/1/
```

### Authentication and Route Preservation
The script automatically detects and preserves:
- Route exposure settings (`networking.kserve.io/visibility=exposed`)
- Authentication configuration (`security.opendatahub.io/enable-auth=true`)
- Service account creation and RBAC setup

## Troubleshooting

### Common Issues

**Error: You are not logged into an OpenShift cluster**
```bash
oc login https://your-cluster-url:6443
```

**Error: Source namespace does not have 'modelmesh-enabled' label**
```bash
oc label namespace your-namespace modelmesh-enabled=true
```

**Error: Target namespace already exists**
- Use `--ignore-existing-ns` flag or delete the existing namespace

**Error: Missing dependencies**
- Install required tools: `oc`, `yq`, `openssl`

### Debug Mode
Use `--debug` to see complete YAML resources before applying:
```bash
./modelmesh-to-raw.sh --from-ns source --target-ns target --debug
```

## Help

```bash
./modelmesh-to-raw.sh --help
```

```
ModelMesh to KServe Raw Deployment Migration Helper

USAGE:
    ./modelmesh-to-raw.sh --from-ns <source-namespace> --target-ns <target-namespace> [OPTIONS]

PARAMETERS:
    --from-ns <namespace>      Source namespace containing ModelMesh InferenceServices
    --target-ns <namespace>    Target namespace for KServe Raw deployment
    --ignore-existing-ns       Skip check if target namespace already exists
    --debug                    Show complete processed resources and wait for user confirmation
    --dry-run                  Save all YAML resources to local directory without applying them
    --page-size <number>       Number of InferenceServices to display per page (default: 10)
    -h, --help                 Show this help message

DESCRIPTION:
    This script migrates InferenceServices from ModelMesh to KServe Raw deployment.
    It will copy models from the source namespace to the target namespace and
    convert them to use KServe Raw deployment method.

    For namespaces with many InferenceServices, use --page-size to control pagination.

EXAMPLES:
    ./modelmesh-to-raw.sh --from-ns modelmesh-serving --target-ns kserve-raw
    ./modelmesh-to-raw.sh --from-ns my-models --target-ns my-models-raw --page-size 5
    ./modelmesh-to-raw.sh --from-ns modelmesh-serving --target-ns kserve-raw --ignore-existing-ns --page-size 20
    ./modelmesh-to-raw.sh --from-ns large-ns --target-ns kserve-raw --dry-run --page-size 50

REQUIREMENTS:
    - oc (OpenShift CLI)
    - yq (YAML processor)
    - Access to both source and target namespaces
```